# Models used in this prototype

This prototype is designed to work with lightweight, CPU-friendly models.

## STT (Speech-to-Text)

- **Model:** faster-whisper `medium`
- **Library:** `faster-whisper`
- **Device:** CPU (`device="cpu"`, `compute_type="int8"`)

Used in `voice/stt.py` via `WhisperModel("medium", device="cpu", compute_type="int8")`.

## VLM (Vision-Language Model) – planned

- Target model for future integration:
  - `Qwen3-VL-4B-Instruct` (for document / table / scan understanding)

Currently, `vlm.py` uses a stub and does not download or load the real VLM yet.

## LLM (Reasoning & Response) – planned

- Target model (for future version):
  - `Qwen3-4B-Instruct` or `Llama-3.1-8B-Instruct`

In this prototype, answers are generated by a rule-based template + RAG stub
(see `rag/rag.py`), without loading a heavy LLM in the repo.
