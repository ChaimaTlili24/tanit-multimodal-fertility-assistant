import gradio as gr
from typing import List, Dict, Any, Optional

from voice.stt import transcribe_audio


# ==============================
#  STUBS / PLACEHOLDERS BACKEND
# ==============================

def simple_stt_transcribe(audio_path: Optional[str]) -> str:
    """
    Wrapper qui utilise le vrai mod√®le faster-whisper d√©fini dans voice/stt.py.
    """
    if audio_path is None:
        return ""
    return transcribe_audio(audio_path)


def simple_image_analysis(image_path: Optional[str]) -> str:
    """
    Stub temporaire pour l'analyse d'image.
    Plus tard : remplac√© par Qwen3-VL-4B-Instruct (VLM).
    """
    if image_path is None:
        return ""
    return "[R√©sum√© simul√© de l'image m√©dicale]"


def simple_pdf_analysis(pdf_path: Optional[str]) -> str:
    """
    Stub temporaire pour l'analyse de PDF.
    Plus tard : extraction pages + VLM ou RAG dessus.
    """
    if pdf_path is None:
        return ""
    return "[R√©sum√© simul√© du PDF m√©dical]"


def simple_rag_answer(user_text: str, extra_context: str) -> str:
    """
    Stub temporaire pour le RAG + LLM.
    Plus tard : remplac√© par (GraphRAG ou RAG vectoriel) + Qwen3-4B-Instruct.
    """
    base_disclaimer = (
        "‚öïÔ∏è *Je suis un assistant √©ducatif sur la fertilit√© et je ne remplace pas un m√©decin.*\n"
        "Pour toute d√©cision m√©dicale ou traitement, consulte toujours un professionnel de sant√©.\n\n"
    )

    response = (
        "Merci pour ta question. Voici une r√©ponse simul√©e (le back-end RAG/LLM "
        "n'est pas encore branch√©) :\n\n"
        f"**Ta question :** {user_text or '[vide]'}\n\n"
        f"**Contexte re√ßu (audio/image/PDF) :** {extra_context or '[aucun]'}"
    )

    return base_disclaimer + response


# ==============================
#  LOGIQUE CHATBOT
# ==============================

def chat_pipeline(
    history: List[Dict[str, Any]],
    user_text: str,
    user_audio,
    user_image,
    user_pdf,
):
    """
    Fonction centrale appel√©e par Gradio √† chaque message.

    - history : liste de messages au format [{"role": "...", "content": "..."}, ...]
    - user_text : texte tap√©
    - user_audio : fichier audio (chemin) ou None
    - user_image : image (chemin) ou None
    - user_pdf : PDF (chemin) ou None
    """

    # 1) Transcription audio (STT r√©el)
    transcribed = simple_stt_transcribe(user_audio)

    # 2) Analyse image (stub)
    image_summary = simple_image_analysis(user_image)

    # 3) Analyse PDF (stub)
    pdf_summary = simple_pdf_analysis(user_pdf)

    # 4) Contexte suppl√©mentaire
    extra_parts = []
    if transcribed:
        extra_parts.append(f"Voix: {transcribed}")
    if image_summary:
        extra_parts.append(f"Image: {image_summary}")
    if pdf_summary:
        extra_parts.append(f"PDF: {pdf_summary}")

    extra_context = " | ".join(extra_parts)

    # 5) Texte final de l'utilisateur = texte tap√© + transcription si pr√©sente
    full_user_text = user_text or ""
    if transcribed:
        full_user_text += f"\n\n[+ Transcription voix]: {transcribed}"

    # 6) G√©n√©ration de la r√©ponse (stub RAG+LLM)
    assistant_message = simple_rag_answer(full_user_text, extra_context)

    # 7) Mise √† jour de l'historique au format messages
    if full_user_text.strip():
        history.append({"role": "user", "content": full_user_text})
    else:
        history.append({"role": "user", "content": "[message vide]"})

    history.append({"role": "assistant", "content": assistant_message})

    # On retourne :
    # - l'historique pour le Chatbot
    # - texte vid√©
    # - audio reset
    # - image reset
    # - pdf reset
    return history, "", None, None, None


# ==============================
#  INTERFACE GRADIO
# ==============================

def build_interface():
    with gr.Blocks(title="Tanit Multimodal Fertility Assistant") as demo:
        gr.Markdown(
            """
            # üß¨ Tanit Multimodal Fertility Assistant (Prototype)

            Assistant multimodal pour accompagner les patientes en fertilit√© :
            texte, voix, images m√©dicales et documents.

            > ‚ö†Ô∏è **Attention :** Ce prototype est strictement √©ducatif.  
            > Il ne remplace en aucun cas un avis m√©dical professionnel.
            """
        )

        with gr.Row():
            with gr.Column(scale=3):
                chatbot = gr.Chatbot(
                    label="Conversation",
                    height=500,
                )

            with gr.Column(scale=1):
                gr.Markdown("### Entr√©e utilisateur")

                text_input = gr.Textbox(
                    label="Message texte",
                    placeholder="D√©cris ta situation, tes r√©sultats, tes questions...",
                    lines=4,
                )

                audio_input = gr.Audio(
                    label="Voix (micro)",
                    sources=["microphone"],
                    type="filepath",
                )

                image_input = gr.Image(
                    label="Image m√©dicale (bilan, courbe, √©chographie...)",
                    type="filepath",
                )

                pdf_input = gr.File(
                    label="Rapport / Analyse au format PDF",
                    file_types=[".pdf"],
                )

                submit_btn = gr.Button("Envoyer")
                clear_btn = gr.Button("Effacer la conversation")

        # Bouton "Envoyer"
        submit_btn.click(
            fn=chat_pipeline,
            inputs=[chatbot, text_input, audio_input, image_input, pdf_input],
            outputs=[chatbot, text_input, audio_input, image_input, pdf_input],
        )

        # Bouton "Effacer"
        def clear_all():
            return [], "", None, None, None

        clear_btn.click(
            fn=clear_all,
            inputs=None,
            outputs=[chatbot, text_input, audio_input, image_input, pdf_input],
        )

    return demo


if __name__ == "__main__":
    demo = build_interface()
    demo.launch()
